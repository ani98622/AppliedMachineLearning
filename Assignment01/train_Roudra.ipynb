{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/cleaned-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally irresistible corporate identity lt r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stock trading gunslinger fanny merrill muzo co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nbelievable new homes made easy im wanting sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color printing special request additional info...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>money get software cds software compatibility ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>research development charges gpg forwarded shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>receipts visit jim thanks invitation visit lsu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>enron case study update wow day super thank mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>interest david please call shirley crenshaw as...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>news aurora update aurora version fastest mode...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_reply  spam\n",
       "0     naturally irresistible corporate identity lt r...         0     1\n",
       "1     stock trading gunslinger fanny merrill muzo co...         0     1\n",
       "2     nbelievable new homes made easy im wanting sho...         0     1\n",
       "3     color printing special request additional info...         0     1\n",
       "4     money get software cds software compatibility ...         0     1\n",
       "...                                                 ...       ...   ...\n",
       "5723  research development charges gpg forwarded shi...         1     0\n",
       "5724  receipts visit jim thanks invitation visit lsu...         1     0\n",
       "5725  enron case study update wow day super thank mu...         1     0\n",
       "5726  interest david please call shirley crenshaw as...         1     0\n",
       "5727  news aurora update aurora version fastest mode...         0     0\n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer()\n",
    "vectorised_data = vectoriser.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_data[0, :20].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.sparse.hstack([vectorised_data, data[\"is_reply\"].values.reshape(-1, 1)])\n",
    "y = data[\"spam\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, splitter, X, y, X_test, y_test):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(splitter.split(X, y)):\n",
    "        X_train = X[train_idx, :]\n",
    "        X_val = X[val_idx, :]\n",
    "\n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy.append(accuracy_score(y_true=y_val, y_pred=y_pred))\n",
    "        recall.append(recall_score(y_true=y_val, y_pred=y_pred))\n",
    "        precision.append(precision_score(y_true=y_val, y_pred=y_pred))\n",
    "\n",
    "    print(\n",
    "        f\"Average accuracy is {100*np.mean(accuracy):.4f} +- {100*np.std(accuracy):.4f} with max {100*np.max(accuracy):.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Average recall is {100*np.mean(recall):.4f} +- {100*np.std(recall):.4f} with max {100*np.max(recall):.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Average precision is {100*np.mean(precision):.4f} +- {100*np.std(precision):.4f} with max {100*np.max(precision):.4f}\"\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 96.0708 +- 0.4134 with max 96.8023\n",
      "Average recall is 93.7910 +- 0.9223 with max 94.9367\n",
      "Average precision is 89.6030 +- 1.2793 with max 91.4634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1713\n",
      "           1       0.92      0.90      0.91       579\n",
      "\n",
      "    accuracy                           0.96      2292\n",
      "   macro avg       0.94      0.94      0.94      2292\n",
      "weighted avg       0.96      0.96      0.96      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier()\n",
    "get_results(model_1, splitter, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 97.4680 +- 0.4567 with max 97.9622\n",
      "Average recall is 89.4767 +- 1.6599 with max 91.1392\n",
      "Average precision is 99.4343 +- 0.6932 with max 100.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1713\n",
      "           1       0.99      0.87      0.93       579\n",
      "\n",
      "    accuracy                           0.97      2292\n",
      "   macro avg       0.98      0.93      0.95      2292\n",
      "weighted avg       0.97      0.97      0.96      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogisticRegression()\n",
    "get_results(model_2, splitter, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 97.8171 +- 0.4018 with max 98.2558\n",
      "Average recall is 96.7024 +- 1.5782 with max 98.7342\n",
      "Average precision is 93.9764 +- 1.0021 with max 95.5414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1713\n",
      "           1       0.95      0.96      0.95       579\n",
      "\n",
      "    accuracy                           0.98      2292\n",
      "   macro avg       0.97      0.97      0.97      2292\n",
      "weighted avg       0.98      0.98      0.98      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = XGBClassifier()\n",
    "get_results(model_3, splitter, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider 3 benchmark models here:\n",
    "* Decision Tree classifier\n",
    "* Logistic Regression\n",
    "* XGboost classifier\n",
    "\n",
    "We consider 3 metrics for each model - accuracy, recall and precision, as the data is also imbalanced.  \n",
    "Best by accuracy: XGBoost classifier  \n",
    "Best by recall: XGboost classifier  \n",
    "Best by precision: Logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGboost classifier to improve accuracy further\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 21:13:32,751] A new study created in memory with name: no-name-265b9a0b-3112-4e42-86b6-401e65d8726c\n",
      "[I 2024-02-05 21:13:50,453] Trial 0 finished with value: -0.9659447885988964 and parameters: {'max_depth': 4, 'learning_rate': 0.07309276338077303, 'subsample': 0.4674374538829663}. Best is trial 0 with value: -0.9659447885988964.\n",
      "[I 2024-02-05 21:14:08,156] Trial 1 finished with value: -0.9621619105649776 and parameters: {'max_depth': 4, 'learning_rate': 0.05358510882221666, 'subsample': 0.5650980682540039}. Best is trial 0 with value: -0.9659447885988964.\n",
      "[I 2024-02-05 21:14:29,102] Trial 2 finished with value: -0.9639082123150876 and parameters: {'max_depth': 5, 'learning_rate': 0.04897457650450214, 'subsample': 0.47421526401415537}. Best is trial 0 with value: -0.9659447885988964.\n",
      "[I 2024-02-05 21:14:45,828] Trial 3 finished with value: -0.9708925730340882 and parameters: {'max_depth': 4, 'learning_rate': 0.09499791078858676, 'subsample': 0.46481837766990847}. Best is trial 3 with value: -0.9708925730340882.\n",
      "[I 2024-02-05 21:15:10,049] Trial 4 finished with value: -0.9743860228157475 and parameters: {'max_depth': 6, 'learning_rate': 0.0644287951233909, 'subsample': 0.47298390553795033}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:15:35,001] Trial 5 finished with value: -0.9644908770860837 and parameters: {'max_depth': 6, 'learning_rate': 0.039495178580973095, 'subsample': 0.5376646625544651}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:15:49,848] Trial 6 finished with value: -0.9478995294675198 and parameters: {'max_depth': 3, 'learning_rate': 0.03788270232527023, 'subsample': 0.6564840885348029}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:16:14,578] Trial 7 finished with value: -0.974096594563488 and parameters: {'max_depth': 6, 'learning_rate': 0.06873571113937359, 'subsample': 0.6400904787834195}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:16:43,926] Trial 8 finished with value: -0.9714765072272435 and parameters: {'max_depth': 7, 'learning_rate': 0.05331867554327113, 'subsample': 0.6294312645062197}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:17:10,207] Trial 9 finished with value: -0.9723494465319387 and parameters: {'max_depth': 6, 'learning_rate': 0.05580541488563543, 'subsample': 0.5188980876871515}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:17:40,458] Trial 10 finished with value: -0.9409177075928371 and parameters: {'max_depth': 7, 'learning_rate': 0.007137370138197235, 'subsample': 0.406676833157802}. Best is trial 4 with value: -0.9743860228157475.\n",
      "[I 2024-02-05 21:18:06,975] Trial 11 finished with value: -0.9749691107274634 and parameters: {'max_depth': 6, 'learning_rate': 0.07358046366677265, 'subsample': 0.688061216986458}. Best is trial 11 with value: -0.9749691107274634.\n",
      "[I 2024-02-05 21:18:29,091] Trial 12 finished with value: -0.9749682644460241 and parameters: {'max_depth': 5, 'learning_rate': 0.08769471693232532, 'subsample': 0.6982487671285644}. Best is trial 11 with value: -0.9749691107274634.\n",
      "[I 2024-02-05 21:18:50,736] Trial 13 finished with value: -0.9755505060763007 and parameters: {'max_depth': 5, 'learning_rate': 0.094639460832171, 'subsample': 0.6924182317779403}. Best is trial 13 with value: -0.9755505060763007.\n",
      "[I 2024-02-05 21:19:12,906] Trial 14 finished with value: -0.975550082935581 and parameters: {'max_depth': 5, 'learning_rate': 0.08281018006910659, 'subsample': 0.6972405431154609}. Best is trial 13 with value: -0.9755505060763007.\n",
      "[I 2024-02-05 21:19:34,486] Trial 15 finished with value: -0.9770052638705529 and parameters: {'max_depth': 5, 'learning_rate': 0.09806024570665134, 'subsample': 0.5856590010393802}. Best is trial 15 with value: -0.9770052638705529.\n",
      "[W 2024-02-05 21:19:34,688] Trial 16 failed with parameters: {'max_depth': 3, 'learning_rate': 0.09983812270777287, 'subsample': 0.605945829174357} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_196670/3250989870.py\", line 21, in objective\n",
      "    model.fit(X_train_cv, y_train_cv)\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/rudy/venvs/general/lib/python3.11/site-packages/xgboost/core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-02-05 21:19:34,701] Trial 16 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[1;32m     29\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study()\n\u001b[0;32m---> 30\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[43], line 21\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_train_cv \u001b[38;5;241m=\u001b[39m y_train[train_idx]\n\u001b[1;32m     20\u001b[0m y_val_cv \u001b[38;5;241m=\u001b[39m y_train[val_idx]\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_cv)\n\u001b[1;32m     24\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39maccuracy_score(y_val_cv, y_pred))\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/general/lib/python3.11/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    splitter = StratifiedKFold(shuffle=True, random_state=42)\n",
    "\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.4, 0.7)\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "    )\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(splitter.split(X_train, y_train)):\n",
    "        X_train_cv = X_train[train_idx, :]\n",
    "        X_val_cv = X_train[val_idx, :]\n",
    "\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        y_val_cv = y_train[val_idx]\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "\n",
    "        scores.append(-accuracy_score(y_val_cv, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'learning_rate': 0.09806024570665134,\n",
       " 'subsample': 0.5856590010393802}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 97.7005 +- 0.6209 with max 98.6919\n",
      "Average recall is 97.8465 +- 1.1727 with max 99.3671\n",
      "Average precision is 92.6046 +- 2.0437 with max 95.1515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1713\n",
      "           1       0.94      0.96      0.95       579\n",
      "\n",
      "    accuracy                           0.97      2292\n",
      "   macro avg       0.96      0.97      0.97      2292\n",
      "weighted avg       0.97      0.97      0.97      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(**params)\n",
    "get_results(model, splitter, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the model overfit a bit as the test accuracy went down to 0.97 from 0.98\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Logistic regression model to improve precision further\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 12:09:23,073] A new study created in memory with name: no-name-f1a49c82-652f-4fdd-92dc-af293ce28ce1\n",
      "[I 2024-02-06 12:09:27,269] Trial 0 finished with value: -0.9912291933418693 and parameters: {'C': 0.8302208011207642, 'l1_ratio': 0.07097188320209749}. Best is trial 0 with value: -0.9912291933418693.\n",
      "[I 2024-02-06 12:09:30,076] Trial 1 finished with value: -0.9900226529071231 and parameters: {'C': 1.035755353056482, 'l1_ratio': 0.1585212240322656}. Best is trial 0 with value: -0.9912291933418693.\n",
      "[I 2024-02-06 12:09:32,087] Trial 2 finished with value: -0.9884698191740446 and parameters: {'C': 0.9812811230982771, 'l1_ratio': 0.21851124218195206}. Best is trial 0 with value: -0.9912291933418693.\n",
      "[I 2024-02-06 12:09:33,549] Trial 3 finished with value: -0.9865418701827835 and parameters: {'C': 0.8690822576585383, 'l1_ratio': 0.26800411790762463}. Best is trial 0 with value: -0.9912291933418693.\n",
      "[I 2024-02-06 12:09:34,783] Trial 4 finished with value: -0.9835694143878287 and parameters: {'C': 0.8887046814259358, 'l1_ratio': 0.35491775285500804}. Best is trial 0 with value: -0.9912291933418693.\n",
      "[I 2024-02-06 12:09:43,753] Trial 5 finished with value: -0.9915705412599823 and parameters: {'C': 0.9908315174709017, 'l1_ratio': 0.03129473730950507}. Best is trial 5 with value: -0.9915705412599823.\n",
      "[I 2024-02-06 12:09:52,912] Trial 6 finished with value: -0.9928703703703704 and parameters: {'C': 0.8792577742911751, 'l1_ratio': 0.024982550930224792}. Best is trial 6 with value: -0.9928703703703704.\n",
      "[I 2024-02-06 12:09:56,215] Trial 7 finished with value: -0.9899509803921568 and parameters: {'C': 1.0562948458830406, 'l1_ratio': 0.12320114080163963}. Best is trial 6 with value: -0.9928703703703704.\n",
      "[I 2024-02-06 12:09:57,300] Trial 8 finished with value: -0.9832663409031148 and parameters: {'C': 0.824960255734098, 'l1_ratio': 0.3819189451825805}. Best is trial 6 with value: -0.9928703703703704.\n",
      "[I 2024-02-06 12:09:59,143] Trial 9 finished with value: -0.9884103042209125 and parameters: {'C': 0.9656764811039116, 'l1_ratio': 0.22757896536490363}. Best is trial 6 with value: -0.9928703703703704.\n",
      "[I 2024-02-06 12:10:17,199] Trial 10 finished with value: -0.9942201356285864 and parameters: {'C': 0.9094655682364874, 'l1_ratio': 0.001930198396377366}. Best is trial 10 with value: -0.9942201356285864.\n",
      "[I 2024-02-06 12:10:35,756] Trial 11 finished with value: -0.9942398342398342 and parameters: {'C': 0.9140473524721335, 'l1_ratio': 0.0028218514946617293}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:10:39,866] Trial 12 finished with value: -0.9899074074074073 and parameters: {'C': 0.9186910334924945, 'l1_ratio': 0.09245063219796051}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:10:55,963] Trial 13 finished with value: -0.9942398342398342 and parameters: {'C': 0.9143817017208957, 'l1_ratio': 0.005806234515607677}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:01,297] Trial 14 finished with value: -0.9899509803921568 and parameters: {'C': 0.9332154615111583, 'l1_ratio': 0.07119905408967739}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:04,380] Trial 15 finished with value: -0.9899074074074073 and parameters: {'C': 1.0122538765090068, 'l1_ratio': 0.1625694899367453}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:06,053] Trial 16 finished with value: -0.9853374584154126 and parameters: {'C': 0.9452095962428311, 'l1_ratio': 0.3092694147064279}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:28,097] Trial 17 finished with value: -0.9941980239646837 and parameters: {'C': 0.8542084276775912, 'l1_ratio': 0.0008874187279155185}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:31,155] Trial 18 finished with value: -0.9895765830084023 and parameters: {'C': 0.8071442280086147, 'l1_ratio': 0.11082262723552092}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:37,271] Trial 19 finished with value: -0.9913888888888888 and parameters: {'C': 0.9108003493614529, 'l1_ratio': 0.054387518679474}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:40,163] Trial 20 finished with value: -0.9900226529071231 and parameters: {'C': 1.0821133866847388, 'l1_ratio': 0.1574173040580953}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:11:53,075] Trial 21 finished with value: -0.9942398342398342 and parameters: {'C': 0.9033578005927679, 'l1_ratio': 0.011738922045131966}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:01,016] Trial 22 finished with value: -0.9914503042596348 and parameters: {'C': 0.9526190589029595, 'l1_ratio': 0.042472221734450165}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:20,805] Trial 23 finished with value: -0.9942201356285864 and parameters: {'C': 0.8987409107421189, 'l1_ratio': 0.0009511083162616731}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:24,676] Trial 24 finished with value: -0.9898340465504646 and parameters: {'C': 0.854686723668289, 'l1_ratio': 0.0857656392121003}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:32,478] Trial 25 finished with value: -0.9914503042596348 and parameters: {'C': 0.9326219609747443, 'l1_ratio': 0.03936657272130388}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:35,537] Trial 26 finished with value: -0.9899074074074073 and parameters: {'C': 0.9707438249029446, 'l1_ratio': 0.12932137171112001}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:40,544] Trial 27 finished with value: -0.9913265838638974 and parameters: {'C': 0.8509354179251886, 'l1_ratio': 0.05790535862040354}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:51,343] Trial 28 finished with value: -0.9928703703703704 and parameters: {'C': 0.9275875911472959, 'l1_ratio': 0.024227003191901363}. Best is trial 11 with value: -0.9942398342398342.\n",
      "[I 2024-02-06 12:12:56,125] Trial 29 finished with value: -0.9899939172749391 and parameters: {'C': 0.9997055279096763, 'l1_ratio': 0.0752300016961173}. Best is trial 11 with value: -0.9942398342398342.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    splitter = StratifiedKFold(shuffle=True, random_state=42)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 0.8, 1.1)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0, 0.4)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"elasticnet\", C=C, solver=\"saga\", l1_ratio=l1_ratio\n",
    "    )\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(splitter.split(X_train, y_train)):\n",
    "        X_train_cv = X_train[train_idx, :]\n",
    "        X_val_cv = X_train[val_idx, :]\n",
    "\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        y_val_cv = y_train[val_idx]\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "\n",
    "        scores.append(-precision_score(y_val_cv, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.9140473524721335, 'l1_ratio': 0.0028218514946617293}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 97.0896 +- 0.5126 with max 97.6710\n",
      "Average recall is 87.8288 +- 1.8836 with max 89.8734\n",
      "Average precision is 99.4220 +- 0.7083 with max 100.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1713\n",
      "           1       0.99      0.87      0.93       579\n",
      "\n",
      "    accuracy                           0.96      2292\n",
      "   macro avg       0.97      0.93      0.95      2292\n",
      "weighted avg       0.97      0.96      0.96      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", **params)\n",
    "get_results(model, splitter, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
